{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_csv('log.csv', header=None)\n",
    "users = pd.read_csv('users.csv',sep='\\t',encoding='KOI8-R')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Теперь нужно сделать так, чтобы с колонками было удобно работать.\n",
    "log.columns = ['user_id','time','bet','win']\n",
    "users.columns = ['user_id','email','geo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "log['time'] = log['time'].str.replace('[','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Посчитайте количество пропусков в столбце time.\n",
    "log['time'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: orange; font-weight: bold; font-size:16pt\">Удаление пропусков</span>\n",
    "\n",
    "Пропуски можно удалять автоматически. Во многих случаях это правильно, так как данные с большим количеством пропусков часто не имеют смысла и не приносят никакой пользы. \n",
    "\n",
    "Удалять данные с пропусками можно с помощью метода ***dropna().***\n",
    "\n",
    "Параметр axis в методе ***dropna()*** говорит методу, по какой оси удалять значения.  \n",
    "\n",
    "Если нужно удалить строки, в которых встречается пропуск (NaN), следует указать axis=0.  Зачем это делать? Например, у нас из 1000 примеров данных про пользователей пропуски есть в пяти. Разумно их удалить, так как их количество пренебрежимо мало.\n",
    "\n",
    "Если нужно удалить столбцы, в которых встречается пропуск (NaN), нужно указывать axis=1. Зачем? Иногда в одном конкретном столбце пропусков настолько много, что с ними просто не хочется возиться - смысла в них все равно почти нет. \n",
    "\n",
    "Еще один интересный параметр - ***subset***. Что он делает? Если передать в него список значений по одной оси (например, названия столбцов) и задать при этом в параметре axis другую ось (в нашем случае 0), то мы удалим те строки, для которых в данных столбцах находится пропуск. То же самое работает и наоборот: нужно поменять axis на 1 и вместо названий столбцов передавать индексы строк."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалите все столбцы, где есть пропуски. Запишите в поле, сколько осталось столбцов в данных после этого.\n",
    "log1 = log.copy()\n",
    "log1.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалите все строки, где есть пропуски. Запишите в поле, сколько осталось строк в данных после этого.\n",
    "\n",
    "log2 = log.copy()\n",
    "log2.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С данными в столбцах bet и win мы разберемся позже: пропуски в этих столбцах требуют особого подхода.\n",
    "\n",
    "А сейчас:\n",
    "\n",
    "если есть пропуски в столбце user_id - удалите столбец user_id,\n",
    "\n",
    "если есть пропуски в столбце time - удалите столбец time.\n",
    "\n",
    "Запишите в поле ответа, количество оставшихся столбцов в данных, после этих действий."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "empty_data = log.isna().sum()[log.isna().sum() > 0].reset_index()\n",
    "empty_data.columns = ['Column', 'Count']\n",
    "display(empty_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log2 = log.copy()\n",
    "log2 = log2.drop(['time'], axis=1)\n",
    "log2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: orange; font-weight: bold; font-size:16pt\">Дубли</span>\n",
    "\n",
    "Дубли - это повторяющиеся строки в данных. В сложных случаях строки могут быть практически одинаковые, но не совсем.\n",
    "\n",
    "Самая частая причина очень банальна: дубли появляются из-за человеческих ошибок или невнимательности.\n",
    "\n",
    "Например, при добавлении записи в систему вы случайно два раза нажали на кнопку \"добавить\". Если система позволяет иметь одинаковые записи, поздравляю - у вас в данных появились дубли.\n",
    "\n",
    "Еще одна причина - слияние баз данных. Например, вы переносите телефоны из контактной книжки (физической, в которую заносили номера ручкой на бумагу, такие были популярны в прошлом) в телефон. Назвали в одном месте Сашу Сашей, а в другом Александром. Да, это тоже дубль, просто сам случай немного более сложный.\n",
    "\n",
    "Сложным случаям типа последнего можно посвятить очень много времени, так что это материал для другого, более продвинутого курса по анализу данных. Скажу лишь, что в каждом конкретном случае подозрительные случаи нужно рассматривать отдельно, это требует кропотливой работы. \n",
    "\n",
    "Мы же рассмотрим простой случай, когда у вас в данных есть идентичные строки."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В pandas есть метод для удаления дублей (дубликатов) - **drop_duplicates()**. Он просто удаляет повторяющиеся строки.\n",
    "\n",
    "У данного метода тоже есть параметр subset, в этом случае нужно передавать список содержащий названия столбцов.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удалите дубли среди столбцов user_id и time. Запишите в поле ниже, сколько осталось строк после удаления дублей.\n",
    "log1 = log[['user_id', 'time']].copy()\n",
    "log1 = log1.drop_duplicates()\n",
    "log1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: orange; font-weight: bold; font-size:16pt\">Преобразование к datetime</span>\n",
    "\n",
    "Для преобразования столбца с датой в виде текста в дату формата datetime (см. Модуль \"С1. Работа с датами\"), необходимо использовать метод to_datetime() в библиотеке pandas.\n",
    "\n",
    "Внутрь метода нужно передать тот столбец, который требуется преобразовать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Уберите лишний символ, преобразуйте признак time к datetime. После этого найдите наибольшую дату и выведите ее без времени.\n",
    "\n",
    "log5 = log.copy()\n",
    "log5 = log5.dropna(axis = 0)\n",
    "log5['time'] = pd.to_datetime(log5['time'])\n",
    "log5['time'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logg = pd.read_csv(\"log.csv\")  \n",
    "logg = logg.dropna()  \n",
    "logg.columns = ['user_id', 'time', 'bet', 'win']  \n",
    "logg['time'] = logg['time'].apply(lambda x: x[1:])  \n",
    "logg['time'] = pd.to_datetime(logg['time'])  \n",
    "logg['time'] = logg.time.apply(lambda x: x.minute)\n",
    "logg['time'].head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: orange; font-weight: bold; font-size:16pt\">Извлечение признаков времени</span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Извлечение признаков времени**\n",
    "\n",
    "Для начала вспомним, что мы можем делать с datetime. Вот примеры атрибутов, по которым мы можем обращаться к данным объектам:\n",
    "\n",
    "year: возвращает год\n",
    "month: возвращает месяц\n",
    "day: возвращает день\n",
    "hour, minute, second - час, минута, секунда\n",
    "dayofweek - день недели, от 0 до 6, где 0 - понедельник, 6 - воскресенье\n",
    "\n",
    "Кроме них, есть и другие интересные атрибуты, советуем посмотреть здесь.\n",
    "\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Timestamp.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ранее в курсе вы разбирали метод apply(). Он позволяет применить определенную функцию к каждому элементу в столбце.\n",
    "\n",
    "В метод apply() можно передавать обычные и lambda-функции.\n",
    "\n",
    "Например, если мы хотим получить столбец, в котором каждым значением будет год из другого столбца (это и есть feature engineering - создание новых признаков из старых), мы можем сделать следующее:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log1 = log.copy()\n",
    "log1['time'] = pd.to_datetime(log1['time'])  \n",
    "year_column = log1['time'].apply(lambda x: x.year) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Библиотека pandas позволяет использовать аксессор dt для упрощения подобной работы:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_colums = log1['time'].dt.year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Аксессор - это атрибут столбца, который хранит переменные типа Timestamp, то есть переменные, которые были строковым представлением времени, а затем изменены с помощью pd.to_datetime(). Если вы попытаетесь обратиться к dt у столбца, в котором лежит что-то отличное от времени, вы получите ошибку.\n",
    "Чуть больше можно увидеть здесь (не забудьте посмотреть в исходный код).\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.dt.html\n",
    "\n",
    "\n",
    "Вы можете пользоваться любым из предложенных выше способов. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Используйте оригинальные данные log.csv, столбец time.\n",
    "# Найдите минуту, которая встречалась в данных чаще всего. Введите ответ в поле ниже.\n",
    "log2 = log.copy()\n",
    "log2['time'] = pd.to_datetime(log2['time']) \n",
    "\n",
    "minute = log2['time'].dt.minute\n",
    "minute.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Найдите месяц, который встречался в данных реже всего. Введите ответ в поле ниже.\n",
    "month = log2['time'].dt.month\n",
    "month.value_counts(ascending = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитайте, сколько дней в данных являются выходными (то есть субботой или воскресеньем). Введите ответ в поле ниже.\n",
    "#V1\n",
    "weekdays = log2['time'].dt.weekday\n",
    "a = weekdays[weekdays == 5].value_counts()\n",
    "b = weekdays[weekdays == 6].value_counts()\n",
    "print(a)\n",
    "print(b)\n",
    "152+131"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# V2\n",
    "log2['weekday'] = log2['time'].dt.weekday\n",
    "#weekday_counts = log2.groupby('weekday').aggregate(sum)\n",
    "log2[(log2['weekday'] == 5) | (log2['weekday'] == 6)].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#V3\n",
    "log2 = log.copy()\n",
    "log2['time'] = pd.to_datetime(log['time']) # convert to date\n",
    "log2['time'].dt.weekday.apply(lambda x: x==5 or x==6).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитайте, какое время дня встречается в данных реже всего. Введите ответ в поле ниже: ночь, утро, день или вечер.\n",
    "# Договоримся, что с 0 до 5 часов - ночь, с 6 до 11 - утро, с 12 до 17 - день, с 18 до 23 - вечер.\n",
    "# Подсказка: можно использовать value_counts(). Кроме этого, потребуется написать функцию, которая преобразует дату во время дня\n",
    "log_d = log.copy()\n",
    "#log_d = log_d.dropna(axis = 0)\n",
    "log_d['time'] = pd.to_datetime(log_d['time'])\n",
    "res = log_d['time'].dt.hour.value_counts().sort_values().reset_index()\n",
    "# res сколько раз каждый час встречается в дата сете\n",
    "print('Night', res.query('0 < index <= 5')['time'].sum())  # night\n",
    "print('Morning', res.query('6 < index <= 11')['time'].sum())  # Morn\n",
    "print('Day', res.query('12 < index <= 17')['time'].sum())  # Day\n",
    "print('Evening', res.query('18 < index <= 23')['time'].sum())  # Even\n",
    "display(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте повторим то, что мы прошли в этой секции. Напишите код, который создаст признак hour из признака time в датасете log.csv. Для этого:\n",
    "\n",
    "1. загрузите датасет log.csv в переменную log, дальше работать будем с ней;\n",
    "\n",
    "2. установите имена столбцов: ['user_id', 'time', 'bet', 'win'];\n",
    "\n",
    "3. избавьтесь от пропусков в log;\n",
    "\n",
    "4. приведите переменную time к подходящему для извлечения признаков виду;\n",
    "\n",
    "5. получите значение часа для каждой строки в переменной time и запишите в столбец hour в log.\n",
    "\n",
    "Результатом будет таблица log со столбцом hour внутри."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_csv('log.csv', header=None)\n",
    "log.columns = ['user_id','time','bet','win']\n",
    "log = log.dropna(axis=0)\n",
    "log['time'] = log['time'].str.replace('[','')\n",
    "log['time'] = pd.to_datetime(log['time'])\n",
    "log['hour'] = log.time.dt.hour\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: orange; font-weight: bold; font-size:16pt\">Обработка пропусков</span>\n",
    "\n",
    "Ранее мы говорили о пропусках - местах в данных, где по какой-то причине ничего нет.\n",
    "\n",
    "Что мы делали с пропусками? Удаляли их.\n",
    "\n",
    "На самом деле, удаление пропусков - довольно грубое решение, потому что мы можем случайно выбросить что-то полезное. Например, у вас есть данные о людях: пол, возраст, цвет глаз, город. При этом для большинства людей не записан цвет глаз. Удалять строки с пропусками может быть неудачным решением -  у нас почти не останется данных. Удалить столбец с цветом глаз - решение получше. Возможно, есть решение еще лучше - например, заполнить все пропуски цветом глаз \"карие\". Ответ на вопрос \"Правильно ли будет так сделать?\" можно получить после уточнения информации: в каких-то странах преобладает один цвет глаз, в каких-то - другой.\n",
    "\n",
    "Поэтому довольно часто можно заполнить пропуски, сделав некоторые обоснованные предположения.\n",
    "\n",
    "Сейчас мы познакомимся с самым простым способом заполнять пропуски - заполнением константой.\n",
    "\n",
    "каждый пропуск в столбце мы заполним одним и тем же числом.\n",
    "\n",
    "Почему мы вообще говорим о заполнении пропусков вместо того, чтобы просто удалить их? Потому что после удаления пропусков у нас останется слишком мало данных, а нам хочется получить какие-то инсайты из них."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: orange; font-weight: bold; font-size:16pt\">Заполнение константой</span>\n",
    "\n",
    "Что такое константа? Это просто число.\n",
    "\n",
    "Посмотрим на признак bet в наших данных (log.csv).\n",
    "\n",
    "\"Bet\" означает \"ставка\".  Некоторые значения в данных заполнены цифрами - поэтому мы можем сделать предположение, что это сумма в рублях, т.е. ставка. \n",
    "\n",
    "Можно также предположить, что если в данных в этом месте пропуск - значит, человек не делал ставку. Другими словами, ставка в данном случае равна 0.\n",
    "\n",
    "Чтобы заполнить пропуски в столбце каким-то значением, можно использовать метод *fillna()* у самого столбца. Аргументом этого метода будет число, которое появится на месте пропусков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитайте, сколько раз люди приходили, но не делали ставок. Для этого заполните пропуски в столбце \n",
    "# bet значением 0 и посчитайте количество таких значений.\n",
    "\n",
    "log = pd.read_csv('log.csv', header=None)\n",
    "log.columns = ['user_id','time','bet','win']\n",
    "log1 = log.copy()\n",
    "log1['bet'] = log1['bet'].fillna(0)\n",
    "log1['bet'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: orange; font-weight: bold; font-size:16pt\">Заполнение с помощью функции</span>\n",
    "\n",
    "Теперь поработаем с признаком win, в котором тоже есть пропуски.\n",
    "\n",
    "Иногда нужно заполнять пропуски не одним и тем же числом, а разными, в зависимости от какого-то условия. Перед нами именно этот случай.\n",
    "\n",
    "Предположим, что если в признаке win находится пропуск, то выигрыша не было. Здесь два возможных случая:\n",
    "\n",
    "Человек не делал ставки и ничего не выиграл. То есть просто пришел, посмотрел и ушел.\n",
    "Человек делал ставку, но не выиграл. Значит, выигрыш на самом деле является отрицательным значением - это проигрыш.\n",
    "Предлагаем вам написать метод, который заполнит пропуски в признаке win в соответствии с предположением выше. \n",
    "\n",
    "Для этого можно применить метод apply() ко всей таблице и передать ему функцию, которая вычисляет размер выигрыша (или проигрыша) по следующей схеме:\n",
    "\n",
    "Если значение в столбце win существует (не пропуск) - вернуть это же значение. Это значит, что человек выиграл.\n",
    "Если вместо значения в столбце win пропуск, вернуть 0.\n",
    "На выходе получится столбец без пропусков. Следующим шагом будет замена старого столбца win на новый."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillna_win(row):  \n",
    "    if row.isna().win == True:\n",
    "        return 0\n",
    "    return row.loc['win'] \n",
    "    \n",
    "new_win = log1.apply(lambda row: fillna_win(row), axis=1)  \n",
    "\n",
    "# Заменяем старый столбец с пропусками на новый без пропусков  \n",
    "log1['win'] = new_win \n",
    "log1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Посчитайте, сколько раз участники ставок проиграли деньги. То есть посчитайте количество строк, \n",
    "# для которых в столбце win находится отрицательное значение.\n",
    "def fillna_win(row):  \n",
    "    if row.win == 0:\n",
    "        return 0 - row.loc['bet']\n",
    "    return row.loc['win'] \n",
    "    \n",
    "new_win = log1.apply(lambda row: fillna_win(row), axis=1)  \n",
    "\n",
    "# Заменяем старый столбец с пропусками на новый без пропусков  \n",
    "log1['win'] = new_win \n",
    "log1['win'].apply(lambda x: x<0).sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте модифицированный в прошлой секции датасет log.csv. Результат запишите числом в поле ниже.\n",
    "\n",
    "Подсказка: можно использовать sum().\n",
    "Создайте признак net, хранящий сумму выигрыша с учетом ставки. Для этого используйте следующий алгоритм:\n",
    "- если значение признака win меньше 0 - присвоить значение признака win признаку net;\n",
    "\n",
    "- во всех остальных случаях - из значения признака win вычтите значение признака bet и полученное значение присвойте признаку net.\n",
    "\n",
    "После этого посчитайте, у скольких людей выигрыш положительный."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def net_net(row):\n",
    "    if row.win < 0:\n",
    "        return row.loc['win']\n",
    "    return row.loc['win'] - row.loc['bet']\n",
    "log1['net'] = log1.apply(lambda row: net_net(row),axis=1)\n",
    "log1['net'].apply(lambda x: x>0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте датасет log.csv, получившийся в результате выполнения предыдущего задания. Посчитайте среднее значение выигрыша (из столбца net) в тех случаях, когда выигрыш больше 0. Результат округлите до целого, отбросив дробную часть.\n",
    "\n",
    "Подсказка: можно использовать mean()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log1[log1['net']>0]['net'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитайте медианное значение выигрыша (из столбца net) в тех случаях, когда выигрыш больше 0. Результат округлите до целого, отбросив дробную часть."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log1[log1['net']>0]['net'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как можно посчитать среднее значение для столбца bet, не учитывая при подсчете пропуски?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log.bet.mean()\n",
    "#log.bet.sum() / log.bet.dropna().shape[0]\n",
    "#log['bet'].dropna().mean()\n",
    "#np.mean(log.bet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте модифицированный исходный датасет log.csv.\n",
    "\n",
    "При модификации датасета log.csv, пропущенные значения в столбцах bet и win замените на 0, cоздайте столбец net, хранящий сумму выигрыша с учетом ставки (для этого из столбца win поэлементно вычтите столбец bet и запишите в новый столбец).\n",
    "\n",
    "Посчитайте, какой процент посещений букмекерской конторы оборачивался ставкой. Для этого поделите количество ставок (значений больше 0) на общее количество посещений конторы. Результат округлите до одного знака после запятой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(len(log1[log1['bet']>0]['win'])/len(log1),3)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте датасет log.csv, получившийся в результате модификации при выполнении первого задания этого блока.\n",
    "\n",
    "Посчитайте среднее значение ставки (из столбца bet) в тех случаях, когда ставка была сделана. Запишите результат, отбросив дробную часть.\n",
    "Подсказка: можно использовать mean()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log1[log1['bet']>0]['bet'].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте датасет log.csv, получившийся в результате модификации при выполнении первого задания этого блока.\n",
    "\n",
    "Посчитайте средний выигрыш (из столбца net) в тех случаях, когда ставка была сделана. В ответ запишите полученное число с отброшенной дробной частью.\n",
    "Пояснение: выигрыш в данном случае означает изменение количества денег и может быть отрицательным. В таком случае это проигрыш.\n",
    "\n",
    "Подсказка: можно использовать mean()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log1[(log1['bet']>0)]['net'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитайте среднее значение потерь при проигрыше (из столбца net). Результат округлите до целого, отбросив дробную часть"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log1[(log1['bet']>0)&(log1['net']<0)]['net'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посчитайте, какой процент ставок заканчивается выигрышем, а какой - проигрышем. Сравните эти значения и ответьте, какое из них больше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(log1[(log1['bet']>0)&(log1['net']<0)])/len(log1)*100) # Lose\n",
    "print(len(log1[(log1['bet']>0)&(log1['net']>0)])/len(log1)*100) # win"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте повторим то, что мы прошли в этой секции. Напишите код, который узнает, чему была равна минимальная ставка и сколько людей сделали такую ставку. Для этого:\n",
    "\n",
    "1. загрузите датасет log.csv;\n",
    "\n",
    "2. посчитайте, чему равна минимальная ставка;\n",
    "\n",
    "3. посчитайте, сколько раз была сделана минимальная ставка, и запишите результат в переменную min_bet_amount в виде целого числа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log = pd.read_csv('log.csv', header=None)\n",
    "log.columns = ['user_id','time','bet','win']\n",
    "log['bet'].min()\n",
    "min_bet_amount = log[log['bet'] == log['bet'].min()]['bet'].count()\n",
    "min_bet_amount"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color: orange; font-weight: bold; font-size:16pt\">Повторение merge/groupby</span>\n",
    "\n",
    "Повторим часть предобработки, которую мы должны были выполнить ранее:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>time</th>\n",
       "      <th>bet</th>\n",
       "      <th>win</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Запись пользователя № - user_919</td>\n",
       "      <td>[2019-01-01 14:06:51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Запись пользователя № - user_973</td>\n",
       "      <td>[2019-01-01 14:51:16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Запись пользователя № - user_903</td>\n",
       "      <td>[2019-01-01 16:31:16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Запись пользователя № - user_954</td>\n",
       "      <td>[2019-01-01 17:17:51</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Запись пользователя № - user_954</td>\n",
       "      <td>[2019-01-01 21:31:18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>Запись пользователя № - user_984</td>\n",
       "      <td>[2019-04-20 9:59:58</td>\n",
       "      <td>9754.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>#error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10054.0</td>\n",
       "      <td>29265.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>#error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10454.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>#error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>#error</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10754.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              user_id                  time      bet      win\n",
       "0    Запись пользователя № - user_919  [2019-01-01 14:06:51      0.0      0.0\n",
       "1    Запись пользователя № - user_973  [2019-01-01 14:51:16      0.0      0.0\n",
       "2    Запись пользователя № - user_903  [2019-01-01 16:31:16      0.0      0.0\n",
       "3    Запись пользователя № - user_954  [2019-01-01 17:17:51      0.0      0.0\n",
       "4    Запись пользователя № - user_954  [2019-01-01 21:31:18      0.0      0.0\n",
       "..                                ...                   ...      ...      ...\n",
       "995  Запись пользователя № - user_984   [2019-04-20 9:59:58   9754.0      0.0\n",
       "996                            #error                   NaN  10054.0  29265.0\n",
       "997                            #error                   NaN  10454.0      0.0\n",
       "998                            #error                   NaN   1000.0      0.0\n",
       "999                            #error                   NaN  10754.0      0.0\n",
       "\n",
       "[1000 rows x 4 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log['bet'] = log['bet'].fillna(0)\n",
    "def fillna_win(row):  \n",
    "    if row.isna().win == True:\n",
    "        return 0\n",
    "    return row.loc['win'] \n",
    "    \n",
    "new_win = log.apply(lambda row: fillna_win(row), axis=1)  \n",
    "\n",
    "# Заменяем старый столбец с пропусками на новый без пропусков  \n",
    "log['win'] = new_win \n",
    "log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def fillna_win(row):  \n",
    "    if row.win == 0:\n",
    "        return 0 - row.loc['bet']\n",
    "    return row.loc['win'] \n",
    "    \n",
    "new_win = log.apply(lambda row: fillna_win(row), axis=1)  \n",
    "\n",
    "# Заменяем старый столбец с пропусками на новый без пропусков  \n",
    "log['win'] = new_win \n",
    "log['win'].apply(lambda x: x<0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "138"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def net_net(row):\n",
    "    if row.win < 0:\n",
    "        return row.loc['win']\n",
    "    return row.loc['win'] - row.loc['bet']\n",
    "log['net'] = log.apply(lambda row: net_net(row),axis=1)\n",
    "log['net'].apply(lambda x: x>0).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-972241e40c73>:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  log['user_id'] = log['user_id'].str.split(' - ').apply(lambda x: x[1])\n"
     ]
    }
   ],
   "source": [
    "users.user_id = users.user_id.apply(lambda x: x.lower()) \n",
    "log['time'] = log['time'].str.replace('[','')\n",
    "log = log[log.user_id != '#error']    \n",
    "log['user_id'] = log['user_id'].str.split(' - ').apply(lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tеперь объединим данные с помощью метода pd.merge():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'user_id'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-1c32fbb1bcc5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0musers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'user_id'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36mmerge\u001b[1;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m     71\u001b[0m     \u001b[0mvalidate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m ) -> \"DataFrame\":\n\u001b[1;32m---> 73\u001b[1;33m     op = _MergeOperation(\n\u001b[0m\u001b[0;32m     74\u001b[0m         \u001b[0mleft\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m         \u001b[0mright\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[0;32m    625\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mright_join_keys\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    626\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin_names\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 627\u001b[1;33m         ) = self._get_merge_keys()\n\u001b[0m\u001b[0;32m    628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    629\u001b[0m         \u001b[1;31m# validate the merge keys dtypes. We may need to coerce\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\reshape\\merge.py\u001b[0m in \u001b[0;36m_get_merge_keys\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    981\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_rkey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    982\u001b[0m                         \u001b[1;32mif\u001b[0m \u001b[0mrk\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 983\u001b[1;33m                             \u001b[0mright_keys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mright\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_label_or_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    984\u001b[0m                         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m                             \u001b[1;31m# work-around for merge_asof(right_index=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m_get_label_or_level_values\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1690\u001b[0m             \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_level_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1691\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1692\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1694\u001b[0m         \u001b[1;31m# Check for duplicates\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'user_id'"
     ]
    }
   ],
   "source": [
    "df = pd.merge(log, users, on='user_id')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Groupby**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('user_id').win.median().median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном случае мы группируем данные по признаку user_id.\n",
    "\n",
    "После этого мы в каждой группе выбираем признак win.\n",
    "\n",
    "Затем мы берем медиану каждой группы по признаку win и на выходе получаем таблицу, в которой индексом является признак user_id. В этой таблице единственный столбец - медиана по каждой группе (то есть по каждому пользователю).\n",
    "\n",
    "Наконец, последний вызов median() дает нам медиану по предыдущему столбцу, то есть возвращает одно число."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте датасет, который получился в результате всех преобразований выше (в том числе, заполнение пропусков). Ответ запишите в поле ниже в виде целого числа (отбросьте дробную часть).\n",
    "\n",
    "Посчитайте медиану баланса по каждому пользователю. Для этого сгруппируйте по пользователям, возьмите признак net, просуммируйте по каждому пользователю и получите медиану."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('user_id').net.sum().median()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сколько раз в среднем каждый человек приходит, не делая ставок, при условии, что у этого человека все-таки есть хотя бы одна ставка? Например: Человек посетил букмекерскую контору 5 раз из них 1 раз сделал ставку, 4 раза нет - условие выполняется. Человек посетил букмекерскую контору 5 раз из них ни разу ставку не сделал - условие не выполняется. Для того, чтобы узнать это, просуммируйте в каждой группе количество записей со ставкой, равной 0, и поделите на общее количество групп. Если при этом в группе нет записей со ставкой больше 0, считаем количество записей в данной группе равным 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero=df[df['bet'] == 0]\n",
    "mid = zero.groupby('user_id')['bet'].count().reset_index()\n",
    "mid.mean()\n",
    "#mid.sort_values('bet').mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте датасет, который получился в результате всех преобразований выше (в том числе, заполнение пропусков). Ответ запишите в поле ниже в виде целого числа - количества дней.\n",
    "\n",
    "Сколько в среднем времени проходит между появлением человека в сервисе и первой ставкой? Считать нужно только тех, кто делал ставку. Для того, чтобы узнать это, напишите метод, считающий минимальное время среди ставок, равных 0, и минимальное время среди ставок больше 0. После этого верните разницу между вторым и первым числом. Пройдитесь по всем группам в цикле. Если в группе нет ставок больше 0, пропустите эту группу. Просуммируйте разницу во времени для каждой группы (с помощью метода, описанного выше) и поделите на количество групп, которые вы не пропустили.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-babf7d4a40c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'time'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mwho_bet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'bet'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m>\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mlis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# create a list for those who bet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwho_bet\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'user_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlis\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df['time'] = pd.to_datetime(df['time'])\n",
    "who_bet = df[df['bet']>0]\n",
    "lis = [] # create a list for those who bet\n",
    "for i in who_bet['user_id']:\n",
    "    if i in lis:\n",
    "        continue\n",
    "    else:\n",
    "        lis.append(i)\n",
    "        \n",
    "who_d_bet = df[df['bet']==0]\n",
    "\n",
    "\n",
    "a = who_bet.groupby('user_id')['time'].min()\n",
    "b = who_d_bet.groupby('user_id')['time'].min()\n",
    "#for i in a['user_id']:\n",
    "    #if i in lis:\n",
    "        #print(i)\n",
    "(a-b).mean()\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте датасет, который получился в результате всех преобразований в прошлой секции (в том числе, заполнение пропусков).\n",
    "\n",
    "Ответ запишите в поле ниже в виде одного слова, с большой буквы.\n",
    "\n",
    "Наибольший суммарный выигрыш среди всех городов имеет Москва. Посчитайте следующий за ней город. Для этого сгруппируйте по городам, возьмите признак win, просуммируйте по каждому городу, отсортируйте и получите второй город."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('geo')['win'].sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Используйте датасет, который получился в результате всех преобразований в прошлой секции (в том числе, заполнение пропусков).\n",
    "\n",
    "Подсказки:\n",
    "\n",
    "1. Можно использовать методы min() и max().\n",
    "\n",
    "2. Учитывайте, что минимальная ставка, это ставка, которая была сделана, т.е. если ставка равна нулю - значит ставки не было.\n",
    "\n",
    "3. Ответ запишите в поле ниже в виде целого числа (нужно отбросить дробную часть).\n",
    "\n",
    "Во сколько раз различаются максимальное и минимальное значение средней ставки по городам? Для того, чтобы это посчитать, нужно сгруппировать по городам, взять среднее от признака bet, найти максимальное и минимальное значения, затем поделить одно на другое."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux = df[df['bet']>0]\n",
    "min_b = aux.groupby('geo')['bet'].mean().min()\n",
    "max_b = aux.groupby('geo')['bet'].mean().max()\n",
    "max_b/min_b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте повторим все, что мы прошли в этой секции. Напишите код, который посчитает, сколько раз пользователи приходили в букмекерскую контору в каждом городе. Для этого:\n",
    "\n",
    "1. загрузите датасеты log.csv и users.csv;\n",
    "\n",
    "2. удалите user_id с ошибкой (#error) и приведите признак user_id к одному виду в обоих датасетах;\n",
    "\n",
    "3. слейте два датасета в один по признаку user_id;\n",
    "\n",
    "4. сгруппируйте данные по правильному признаку (какому - вам нужно понять самим), затем выберите user_id и воспользуйтесь функцией count() для подсчета наблюдений в каждой группе;\n",
    "\n",
    "5. результат запишите в sample2 (объект Series)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log = pd.read_csv('log.csv', header=None)\n",
    "users = pd.read_csv('users.csv',sep='\\t',encoding='KOI8-R')\n",
    "log.columns = ['user_id','time','bet','win']\n",
    "users.columns = ['user_id','email','geo']\n",
    "\n",
    "users.user_id = users.user_id.apply(lambda x: x.lower()) \n",
    "log = log[log.user_id != '#error']    \n",
    "log['user_id'] = log['user_id'].str.split(' - ').apply(lambda x: x[1])\n",
    "\n",
    "df = pd.merge(log, users, on='user_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "geo\n",
       "Арзангелтск         96\n",
       "Воронеж             88\n",
       "Екатеринбург        49\n",
       "Ижевск              61\n",
       "Казань              66\n",
       "Краснодар           86\n",
       "Красноярск          56\n",
       "Москва              61\n",
       "Пермь               55\n",
       "Санкт-Петербург    115\n",
       "Ставрополь          36\n",
       "Тюмень              32\n",
       "Хабаровск           60\n",
       "Ярославль           89\n",
       "Name: user_id, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample2 = df.groupby('geo')['user_id'].count()\n",
    "sample2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bet</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [bet]\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bet = df.groupby('user_id')[['bet']].sum()\n",
    "df_bet0 = df_bet[df_bet.bet == 0]\n",
    "df_bet0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
